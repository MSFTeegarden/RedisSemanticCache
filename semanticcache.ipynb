{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Cache Documentation: https://python.langchain.com/docs/integrations/llms/llm_caching#redis-cache\n",
    "LLM Documentation: https://python.langchain.com/docs/integrations/llms/azure_openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (0.0.323)\n",
      "Requirement already satisfied: redis in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (5.0.1)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.5.1-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from openai) (3.8.6)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (2.0.22)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (0.0.51)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2023.10.3-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from aiohttp->openai) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from requests>=2.20->openai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kyteegar\\semanticcache1\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Using cached tiktoken-0.5.1-cp39-cp39-win_amd64.whl (760 kB)\n",
      "Using cached regex-2023.10.3-cp39-cp39-win_amd64.whl (269 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.10.3 tiktoken-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai langchain redis tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import redis\n",
    "import os\n",
    "import langchain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import RedisSemanticCache\n",
    "import time\n",
    "\n",
    "\n",
    "openai_api_base=\"<your-azure-open-ai-endpoint>\"\n",
    "openai_api_type=\"azure\" # you need this if you're using Azure Open AI service\n",
    "openai_api_key=\"<your-azure-openai-key>\"\n",
    "openai_api_version=\"2023-05-15\"\n",
    "\n",
    "# make sure you have an LLM deployed in your Azure Open AI account. In this example, I used the GPT 3.5 turbo instruct model. My deployment was named \"gpt35instruct\".\n",
    "llm = AzureOpenAI(\n",
    "    deployment_name=\"gpt35instruct\",\n",
    "    model_name=\"gpt-35-turbo-instruct\",\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_version=openai_api_version,\n",
    ")\n",
    "# make sure you have an embeddings model deployed in your Azure Open AI account. In this example, I used the text embedding ada 002 model. My deployment was named \"textembedding\".\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=\"textembedding\",\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    openai_api_key=openai_api_key,\n",
    "    openai_api_base=openai_api_base,\n",
    "    openai_api_version=openai_api_version,\n",
    ")\n",
    "\n",
    "\n",
    "REDIS_ENDPOINT = \"<your-azure-redis-endpoint>\" # must include port at the end. e.g. \"redisdemo.eastus.redisenterprise.cache.azure.net:10000\"\n",
    "REDIS_PASSWORD = \"<your-redis-password>\"\n",
    "\n",
    "# create a connection string for the Redis Vector Store. Uses Redis-py format: https://redis-py.readthedocs.io/en/stable/connections.html#redis.Redis.from_url\n",
    "# This example assumes TLS is enabled. If not, use \"redis://\" instead of \"rediss://\n",
    "redis_url = \"rediss://:\" + REDIS_PASSWORD + \"@\"+ REDIS_ENDPOINT\n",
    "\n",
    "# set up the semantic cache for your llm\n",
    "set_llm_cache(RedisSemanticCache(redis_url = redis_url, embedding=embeddings, score_threshold=.05))\n",
    "\n",
    "#note: you can use score_threshold to change how sensitive the semantic cache is. The lower the score, the less likely it is to use a cached result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Oh, the sight of a cute puppy,\n",
      "Makes my heart skip a beat,\n",
      "With their wagging tails and floppy ears,\n",
      "They are simply too sweet.\n",
      "\n",
      "Their tiny paws and curious eyes,\n",
      "Filled with innocence and glee,\n",
      "They bring joy to our lives,\n",
      "In every wag and bark we see.\n",
      "\n",
      "Their fur, so soft and fluffy,\n",
      "A delight to touch and hold,\n",
      "They bring warmth to our hearts,\n",
      "Even when the world is cold.\n",
      "\n",
      "Their playful nature knows no bounds,\n",
      "As they chase their tails in delight,\n",
      "Their energy is infectious,\n",
      "A true bundle of pure delight.\n",
      "\n",
      "They snuggle close and give wet kisses,\n",
      "With their unconditional love,\n",
      "They make our days brighter,\n",
      "And our spirits soar above.\n",
      "\n",
      "With every clumsy step they take,\n",
      "And every toy they chew,\n",
      "They teach us to appreciate,\n",
      "The simple joys in life, so true.\n",
      "\n",
      "Oh, how I adore these cute puppies,\n",
      "With their boundless love and grace,\n",
      "They are a reminder of the beauty,\n",
      "In this world, and every place.\n",
      "\n",
      "So let us cherish these furry friends,\n",
      "And hold them close with care,\n",
      "For they are more than just pets,\n",
      "They are a love beyond compare.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 190 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = llm(\"Please write a poem about cute puppies\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# calculate tokens required\n",
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "response_tokens = len(encoding.encode(response))\n",
    "query_tokens = len(encoding.encode(\"Please write a poem about cute puppies\"))\n",
    "print(response_tokens)\n",
    "print(query_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
